{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "res=\"./data_preprocessing/\"\n",
    "List=[]\n",
    "for i in range (10192,10540):\n",
    "     path = res + str(i) + \".txt\"\n",
    "     if os.path.exists(path) == True:\n",
    "          List=List+[path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in dictionary: ['c', 'cong', 'gun', 'hixhix', 'hot', 'len', 'man', 'may', 'non', 'turn', 'va']\n",
      "Vector Bag-of-Word:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Words in dictionary: ['ban', 'bit', 'bye', 'bảo_vệ', 'ch', 'chat', 'cho_rồi', 'con', 'cong', 'cut', 'dot', 'hi', 'hung', 'ing', 'k', 'len', 'let', 'long', 'lui', 'lễ_phép', 'man', 'mi', 'quay', 'que', 'r', 'ra', 'rut', 'thing', 'trả_lời', 'turn', 'xem_lại', 'xin_lỗi', 'đàng_hoàng', 'đường']\n",
      "Vector Bag-of-Word:\n",
      "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 2, 1, 1, 2, 1, 4, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Words in dictionary: ['ban', 'bao_giờ', 'c', 'ca', 'ch', 'chin', 'hay', 'igni', 'không_thể', 'len', 'mac', 'man', 'nhạt_nhẽo', 'ni', 'non', 'nước_dùng', 'peri', 'que', 'thái_độ', 'turn', 'tình_cờ', 'vo', 'ăn_ở', 'được', 'ở']\n",
      "Vector Bag-of-Word:\n",
      "[2, 1, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
      "Words in dictionary: ['bad', 'big', 'bu', 'c', 'ca', 'ch', 'chi', 'com', 'cut', 'delhi', 'du', 'food', 'gin', 'go', 'ha', 'hen', 'hi', 'la', 'long', 'may', 'mo', 'mud', 'n', 'na', 'non', 'p', 'peu', 'que', 'ra', 'review', 'tank', 'thing', 'ti', 'tie', 'tokyo', 'trunk', 'turn', 'u', 'va', 'vi', 'vo', 'đươ', 'ơ']\n",
      "Vector Bag-of-Word:\n",
      "[1, 1, 2, 5, 1, 3, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 2, 2, 1, 1, 2]\n",
      "Words in dictionary: ['ban', 'bit', 'burn', 'c', 'chief', 'có_thể', 'g', 'gun', 'hi_vọng', 'hôm_qua', 'khoảng', 'lui', 'man', 'mở_cửa', 'night', 'put', 'thing', 'thông_báo', 'ti', 'tm', 'tra', 'turn']\n",
      "Vector Bag-of-Word:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1]\n",
      "Words in dictionary: ['bây_giờ', 'bình_thường', 'c', 'ca', 'ch', 'china', 'chất_lượng', 'cũng_như', 'gin', 'go', 'khan', 'let', 'mac', 'man', 'mi', 'ney', 'ngoài', 'nhân_viên', 'non', 'nổi_tiếng', 'phục_vụ', 'sea', 'thing', 'thái_độ', 'thực_đơn', 'tm', 'try', 'turn', 'đơn_điệu', 'được', 'đặc_sắc']\n",
      "Vector Bag-of-Word:\n",
      "[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1]\n",
      "Words in dictionary: ['bang', 'ch', 'chi', 'em', 'go', 'hung', 'k', 'khách_hàng', 'la_liệt', 'lay', 'long', 'mi', 'mind', 'nom', 'non', 'nước', 'phục_vụ', 'thing', 'thân_thiện', 'thậm_chí', 'time', 'tm', 'được', 'đầu_tư', 'đồ_ăn']\n",
      "Vector Bag-of-Word:\n",
      "[1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from os import link, read\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def bag_of_word(sentence):\n",
    "    vector = []\n",
    "\n",
    "    for word in dictionary:\n",
    "        count = 0        \n",
    "        \n",
    "        for w in sentence:\n",
    "            if w == word:\n",
    "                count += 1\n",
    "        vector.append(count)\n",
    "    return vector\n",
    "\n",
    "for path in List:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text=f.read()\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(sentences)):\n",
    "        words = nltk.word_tokenize(sentences[i])\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "        sentences[i] = ' '.join(words)\n",
    "\n",
    "    texts=[]\n",
    "    for x in sentences:\n",
    "        texts.append([text for text in [x for x in x.lower().split()]])\n",
    "\n",
    "    dictionary = sorted(list(set(reduce(lambda x, y: x + y, texts))))\n",
    "    print(\"Words in dictionary:\",dictionary)\n",
    "\n",
    "    print(\"Vector Bag-of-Word:\")\n",
    "    for sentence in texts:\n",
    "        print(bag_of_word(sentence))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
